{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "419c18d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import regex as re\n",
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from spacy.lang.en import English\n",
    "#from spacy.tokenizer import Tokenizer\n",
    "from tqdm import tqdm\n",
    "import contractions\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize # must use this for collocations, spacy tokeniser seems incompatible when calcualting pmi score\n",
    "from unidecode import unidecode\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "36e4b77f-7b83-40a4-abf6-5074b6bbbd16",
   "metadata": {},
   "source": [
    "import os\n",
    "#os.environ['TF_XLA_FLAGS'] = '--tf_xla_enable_xla_devices'\n",
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "print(\"GPUs: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f847e73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 369047 entries, 0 to 369046\n",
      "Data columns (total 7 columns):\n",
      " #   Column      Non-Null Count   Dtype         \n",
      "---  ------      --------------   -----         \n",
      " 0   author      181799 non-null  object        \n",
      " 1   date        369047 non-null  datetime64[ns]\n",
      " 2   domain      369047 non-null  object        \n",
      " 3   title       368962 non-null  object        \n",
      " 4   url         369047 non-null  object        \n",
      " 5   content     369047 non-null  object        \n",
      " 6   topic_area  369047 non-null  object        \n",
      "dtypes: datetime64[ns](1), object(6)\n",
      "memory usage: 19.7+ MB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>date</th>\n",
       "      <th>domain</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>content</th>\n",
       "      <th>topic_area</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Thomas Hughes</td>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>marketbeat</td>\n",
       "      <td>Three Industrial Giants You Should Own In 2020</td>\n",
       "      <td>https://www.marketbeat.com/originals/three-ind...</td>\n",
       "      <td>With the end of the year just around the corne...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Thomas Hughes</td>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>marketbeat</td>\n",
       "      <td>Labor Stocks Are Going To Break Out In 2020</td>\n",
       "      <td>https://www.marketbeat.com/originals/labor-sto...</td>\n",
       "      <td>The labor markets were one of the most closely...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Steve Anderson</td>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>marketbeat</td>\n",
       "      <td>Tesla (TSLA) Breaks Shipment Record, Beats Est...</td>\n",
       "      <td>https://www.marketbeat.com/originals/teal-brea...</td>\n",
       "      <td>It could be forgiven, that some might think th...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            author       date      domain  \\\n",
       "0    Thomas Hughes 2020-01-02  marketbeat   \n",
       "1    Thomas Hughes 2020-01-03  marketbeat   \n",
       "2  Steve Anderson  2020-01-03  marketbeat   \n",
       "\n",
       "                                               title  \\\n",
       "0     Three Industrial Giants You Should Own In 2020   \n",
       "1        Labor Stocks Are Going To Break Out In 2020   \n",
       "2  Tesla (TSLA) Breaks Shipment Record, Beats Est...   \n",
       "\n",
       "                                                 url  \\\n",
       "0  https://www.marketbeat.com/originals/three-ind...   \n",
       "1  https://www.marketbeat.com/originals/labor-sto...   \n",
       "2  https://www.marketbeat.com/originals/teal-brea...   \n",
       "\n",
       "                                             content topic_area  \n",
       "0  With the end of the year just around the corne...   business  \n",
       "1  The labor markets were one of the most closely...   business  \n",
       "2  It could be forgiven, that some might think th...   business  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./data/covid19_articles_20201231.csv')\n",
    "\n",
    "# Date to datetime\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "print(df.info())\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad55feb-61c1-43c8-bf96-411c739bde7e",
   "metadata": {},
   "source": [
    "### Drop Article Functions\n",
    "* Drop duplicates\n",
    "* Drop long articles\n",
    "* Drop articles that are annual reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e45bb78c-c564-4358-9715-3b1fce3c740a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_articles(df):\n",
    "    \n",
    "    df = df.copy()\n",
    "    \n",
    "    # Drop duplicates\n",
    "    num_articles_pre_drop = len(df)\n",
    "    df = df.drop_duplicates(subset='content')\n",
    "    print(f'no. articles dropped: {num_articles_pre_drop - len(df)} duplicates')\n",
    "    \n",
    "    # Drop long articles\n",
    "    num_articles_pre_drop = len(df)\n",
    "    df = df[df['content'].str.len() < 50000]\n",
    "    print(f'no. articles dropped: {num_articles_pre_drop - len(df)} long articles')\n",
    "    \n",
    "    # Drop short articles\n",
    "    num_articles_pre_drop = len(df)\n",
    "    df = df[df['content'].str.len() > 50]\n",
    "    print(f'no. articles dropped: {num_articles_pre_drop - len(df)} short articles')\n",
    "    \n",
    "    # Drop articles with annual report as title\n",
    "    num_articles_pre_drop = len(df)\n",
    "    df = df[~df['title'].str.contains(\"Annual Report | Half-yearly financial report | half-year report\", na=False)]\n",
    "    print(f'no. articles dropped: {num_articles_pre_drop - len(df)} annual reports')\n",
    "    \n",
    "    # Drop earnings conference call transcripts\n",
    "    num_articles_pre_drop = len(df)\n",
    "    df = df[~df['title'].str.contains(\"earnings conference call | transcript\", na=False)]\n",
    "    print(f'no. articles dropped: {num_articles_pre_drop - len(df)} earnings call transcripts')\n",
    "    \n",
    "    print('no. of articles: ', len(df))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09ffd888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. articles dropped: 127 duplicates\n",
      "no. articles dropped: 3095 long articles\n",
      "no. articles dropped: 9 short articles\n",
      "no. articles dropped: 139 annual reports\n",
      "no. articles dropped: 477 earnings call transcripts\n",
      "no. of articles:  365200\n"
     ]
    }
   ],
   "source": [
    "test = drop_articles(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f34333e",
   "metadata": {},
   "source": [
    "### Cleaning Functions\n",
    "\n",
    "TO DO\n",
    "* Normalise plurals - maybe - https://stackoverflow.com/questions/32404666/python-generating-the-plural-noun-of-a-singular-noun/41830129\n",
    "* Make code more efficient - tokens.split pass into function rather than doing in every function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d263e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_text(text):\n",
    "    \"\"\"\n",
    "    : remove new line and trailing leading whitespace\n",
    "    \"\"\"\n",
    "    return text.strip()\n",
    "\n",
    "def is_number(text):\n",
    "    \"\"\"\n",
    "    :utility function to test if text is a number\n",
    "    \"\"\"\n",
    "    try:\n",
    "        float(text) if '.' in text else int(text)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "def remove_numbers(text):\n",
    "    \"\"\"\n",
    "    :remove numbers, percentages, dollar values\n",
    "    \"\"\"\n",
    "    \n",
    "    regex_percent = re.compile(r'[\\-\\+]?[\\d]+\\.?\\d*[%]+\\.?') # e.g. 3%, -3.8%\n",
    "    regex_number_fullstop = re.compile(r'\\d+[\\.]') # e.g. 2019.\n",
    "    regex_number_fullstop_2 = re.compile(r'\\d+\\.\\d+\\.') # e.g. 2019.28.\n",
    "    regex_dollar_number = re.compile(r'[\\$]+[\\d,]+\\.?\\d*') # e.g. $2 or $2.4567\n",
    "    regex_thousands = re.compile(r'\\d+\\,\\d+') # e.g. 4,000 or 4,000.00\n",
    "    regex_thousands_2 = re.compile(r'\\d+\\,\\d+\\W') # e.g. 4,000 or 4,000.00\n",
    "    \n",
    "    percent = regex_percent.findall(text)\n",
    "    number_fullstop = regex_number_fullstop.findall(text)\n",
    "    number_fullstop_2 = regex_number_fullstop_2.findall(text)\n",
    "    dollar_number = regex_dollar_number.findall(text)\n",
    "    thousands = regex_thousands.findall(text)\n",
    "    thousands_2 = regex_thousands_2.findall(text)\n",
    "\n",
    "    word_removals = percent + number_fullstop + number_fullstop_2 + dollar_number + thousands + thousands_2\n",
    "\n",
    "    tokens = text.split(\" \")\n",
    "    \n",
    "    # remove integers and floats\n",
    "    tokens_filtered = [word for word in tokens if not is_number(word)]\n",
    "    # remove percentages\n",
    "    tokens_filtered = [word for word in tokens_filtered if word not in word_removals]\n",
    "    \n",
    "    text_clean = (\" \").join(tokens_filtered)\n",
    "    \n",
    "    return text_clean\n",
    "\n",
    "def remove_emails_tags(text):\n",
    "    \"\"\"\n",
    "    : remove emails and tags (e.g @sleepingbeauty)\n",
    "    \"\"\"\n",
    "    # Add a space before commas to seperate from preceeding word\n",
    "    text = re.sub(\",\", \" ,\", text)\n",
    "    \n",
    "    regex_email = re.compile(r'[\\w\\.-]+@[\\w\\.-]+.') # email with character at end, e.g. space\n",
    "    regex_email2 = re.compile(r'[\\w\\.-]+@[\\w\\.-]+') # email with no character at end\n",
    "    regex_tag = re.compile(r'@[\\w\\.-]+') # tags e.g @sleepingbeauty\n",
    "    regex_tag = re.compile(r'\\S+@[\\w\\.-]+.') # tags plust character e.g (@sleepingbeauty)\n",
    "    email = regex_email.findall(text)\n",
    "    email2 = regex_email2.findall(text)\n",
    "    tag = regex_tag.findall(text)\n",
    "    word_removals = email + email2 + tag\n",
    "    \n",
    "    tokens = text.split(\" \")\n",
    "    # Remove if email\n",
    "    tokens_filtered = [word for word in tokens if word not in word_removals]\n",
    "    \n",
    "    text_clean = (\" \").join(tokens_filtered)\n",
    "    \n",
    "    return text_clean\n",
    "\n",
    "def remove_contraction_possesive_apostrophes(text):\n",
    "    \"\"\"\n",
    "    :remove contraction e.g. can't, won't, she'll -> cant, and possesive apostrophes +s e.g The president's dog -> president\n",
    "    note: not completely correct as removes 's from e.g. that's which is a contraction rather that possessive, but this is not seen as an issue\n",
    "    \"\"\"\n",
    "    \n",
    "    #regex_contraction = re.compile(r\"[a-zA-Z]+'[a-rt-zA-RT-Z]+|[a-zA-Z]+’[a-rt-zA-RT-Z]+\")\n",
    "    #contraction = regex_contraction.findall(text)\n",
    "    \n",
    "    regex_possessive = re.compile(r\"[a-zA-Z]+'[sS]+|[a-zA-Z]+’[sS]+\")\n",
    "    possessive = regex_possessive.findall(text)\n",
    "    \n",
    "    tokens = text.split(\" \")\n",
    "    \n",
    "    # remove contractions\n",
    "    #tokens_filtered = [word if word not in contraction else word.replace(\"'\", \"\").replace(\"’\",\"\") for word in tokens]\n",
    "    # replace 's\n",
    "    tokens_filtered = [word if word not in possessive else word.replace(\"'s\", \"\").replace(\"’s\",\"\").replace(\"'S\",\"\").replace(\"’S\",\"\") for word in tokens]\n",
    "    \n",
    "    text_clean = (\" \").join(tokens_filtered)\n",
    "    \n",
    "    return text_clean\n",
    "\n",
    "def expand_contractions(text):\n",
    "    \n",
    "    try:\n",
    "        expanded_text = contractions.fix(text)\n",
    "    except:\n",
    "        expanded_text = text\n",
    "        \n",
    "    return expanded_text\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    \"\"\"\n",
    "    :remove english punctuation (note: does not remove non english punctuation, e.g german version of \")\n",
    "    \"\"\"\n",
    "    return text.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "def remove_long_words(text):\n",
    "    \"\"\"\n",
    "    :remove words that are likely not english or html references\n",
    "    \"\"\"\n",
    "    tokens = text.split(\" \")\n",
    "    tokens_filtered = [word for word in tokens if len(word) < 20 ]\n",
    "    text_clean = (\" \").join(tokens_filtered)\n",
    "    \n",
    "    return text_clean\n",
    "\n",
    "def lowercase_text(text):\n",
    "    \"\"\"\n",
    "    :convert text to lowercase\n",
    "    \"\"\"\n",
    "    return text.lower()\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    \"\"\"\n",
    "    :remove stopwords\n",
    "    \"\"\"\n",
    "    stop_word_list = spacy.lang.en.stop_words.STOP_WORDS\n",
    "    tokens = text.split(\" \")\n",
    "    tokens_filtered = [word for word in tokens if word not in stop_word_list]\n",
    "    tokens_filtered = [word for word in tokens_filtered if word != \" \"]\n",
    "    tokens_filtered = [word for word in tokens_filtered if word != \"\"]\n",
    "    text_clean = (\" \").join(tokens_filtered)\n",
    "    return text_clean\n",
    "    \n",
    "def remove_accents_non_english_char(text):\n",
    "    \"\"\"\n",
    "    :remove accents and non english characters (includes non english punctuation)\n",
    "    \"\"\"\n",
    "    #text_clean = unidecode(text, \"utf-8\")\n",
    "    text_clean = unidecode(text)\n",
    "\n",
    "    return text_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2540aa01-20af-4942-a626-6e5d33384c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "#expand_contractions(\"they're theyre Theyre wont won't Steve's, he's\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac9c0947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it could be forgiven  that some might think that tesla nasdaq tsla was little more than a big pile of pieinthesky nonsense yet it seems  these days  that we hear a lot of positive buzz around this maker of electric vehicles that implores we take this company seriously one more brick in the wall of credibility has fallen into place  as recently  tesla reported its delivery and production numbers for the fourth quarter of the news is shockingly good  as evidenced by key phrases like recordbreaking production is off and running the key number for the fourth quarter at tesla was which is how many vehicles were delivered worldwide for the period this not only beat wall street estimates by vehiclesestimates said would go out the doorbut it also beat a goal set up by musk earlier in the year interestingly  if tesla had matched the street estimates  it still would have met musk own goal  so it is a surprise for both entities tesla noted that  in  it delivered a grand total of around vehicles  a move which represents a increase from 2018s figures good news by any stretch  and sufficient to drive not only a two percent price increase  but part of an increase of overall for the last year it is given some of those gains back as of this writing  but it is still handily off yesterday close of a watched pot that is boiling pretty hard it is not surprising that tesla delivery figures are watched closely they are considered the best way to figure out tesla sales numberswhich is reasonable enough obviously they are not selling vehicles they are not delivering  unexpected cancellations asideand the numbers spotted so far have been substantial documentwritea targetblank relnofollow hrefhttpswwwame  wall street legend has just made a rather large discovery\n",
      "\n",
      "for the past several months  he is been tracking warren buffett top holdings\n",
      "\n",
      "and what he found was surprising tesla was expected to deliver of its model vehicles  as well as of its model s and of its model x  according to word from factset yet tesla announced sound if approximate defeats on all those fronts  noting that it shipped model vehicles  along with model s and model x vehicles while there is some wiggle room for defeat in that last quotewhy they did not say how many of each was shipped rather than putting the two together in their own bloc is unclearit would mean a serious win in one category or the other if  for example  its model x sales faltered and they only got out the door  that would mean they shipped model s units  or better than overestimates additionally  the production numbers at tesla are looking sharp as well while the company was setting production records back in the third quarter of  they were actually delivering more cars than they produced yet the company has put a clear focus on production  putting largely to rest concerns that tesla total manufacturing capability would leave it a niche product tesla continues to build a charge as good as the numbers have been around tesla lately  the buzz has been even better just after christmas  we saw wedbush securities hike its price target from to a share meeting that price target  meanwhile  would require a substantial drop in the current share price the last few weeks have been enough to take the wind out of predictions from credit suisse analyst dan levy  who suggesting a potential percent drop in the stock price to come while that was based on the appearance of extra competition in the fieldand not out of line  either  as ford nyse f recently noted that reservations for the upcoming mache electric mustang were fullthe production and delivery numbers emerging from tesla suggests it is in position to effectively take on some competition there is no doubt that tesla has been gaining a lot of ground lately it is already beaten short sellers on at least one notable occasion  and with bull cases suggesting the stock still has room to run over even its current levels  the idea that tesla is stymied in its push to get more electric vehicles into the market seems flawed at best what is more  with tesla having some unexpected advantages in its arsenal  like its rapid improvements in battery technology  there is the possibility that the company could diversify and give itself a couple of extra revenue streams  a point that seldom goes amiss in the face of increased competition people seem interested in electric vehicles  and right now  tesla is leading the way in their provision competition is likely to followthese figures are too substantial not to suggest that others want a piece of the piebut with that diversification potential on hand  tesla might well be able to hold out and see the levels that only the most ardent bulls can see right now   oil stocks that may not survive the current crisis what would you think of the longterm prospects of a business that paid you to buy their products that is an oversimplification of what occurred to the may futures contract for oil on april the price for that contract sold for a negative price for the first time in history\n",
      "\n",
      "the crisis befalling the oil companies at this time can best be described as only the strongest survive there is just no way the oil companies can possibly handle month after month of rockbottom oil prices\n",
      "\n",
      "the problem is almost comically simple to understand there is a massively reduced demand for oil as millions of americans are following mitigation orders ranging from social distancing guidelines to more restrictive shelter in place orders at the same time  the market is trying to absorb the oversupply of oil that came from russia and saudi arabia\n",
      "\n",
      "however  when the year started  things looked like it might be business as usual for oil producers the yous economy was humming along and there was talk that the second half of the year might finally bring the boost to oil prices that many companies badly needed\n",
      "\n",
      "however  since the middle of february  the bottom has dropped out of the market in general  and oil prices have been one of the main sectors to feel the impact\n",
      "\n",
      "initially  investors tried to remain optimistic a month ago  investors thought that the economy might be reopening sooner rather than later however  the exact timing of the reopening is about as fluid as a barrel of oil and with it looking more likely that there will be more demand destruction at least through may  there is very little to prop up the stock of any oil companies\n",
      "\n",
      "and that means that  in all likelihood  there will not be room left for some oil companies we have highlighted five oil stocks that have a strong probability of not surviving the chaos surrounding the coronavirus and our nation response view the oil stocks that may not survive the current crisis complete the form below to receive the latest headlines and analysts recommendations for your stocks with our free daily email newsletter\n"
     ]
    }
   ],
   "source": [
    "test = strip_text(df['content'][2])\n",
    "test = remove_numbers(test)\n",
    "test = remove_emails_tags(test)\n",
    "test = expand_contractions(test)\n",
    "test = remove_contraction_possesive_apostrophes(test)\n",
    "test = remove_accents_non_english_char(test)\n",
    "test = remove_punctuation(test)\n",
    "test = remove_numbers(test)\n",
    "test = remove_long_words(test)\n",
    "test = lowercase_text(test)\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "492c99ba-6927-4fff-a748-1f207ec9cb4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'forgiven think tesla nasdaq tsla little big pile pieinthesky nonsense days hear lot positive buzz maker electric vehicles implores company seriously brick wall credibility fallen place recently tesla reported delivery production numbers fourth quarter news shockingly good evidenced key phrases like recordbreaking production running key number fourth quarter tesla vehicles delivered worldwide period beat wall street estimates vehiclesestimates said doorbut beat goal set musk earlier year interestingly tesla matched street estimates met musk goal surprise entities tesla noted delivered grand total vehicles represents increase 2018s figures good news stretch sufficient drive percent price increase increase overall year given gains writing handily yesterday close watched pot boiling pretty hard surprising tesla delivery figures watched closely considered best way figure tesla sales numberswhich reasonable obviously selling vehicles delivering unexpected cancellations asideand numbers spotted far substantial documentwritea targetblank relnofollow hrefhttpswwwame wall street legend large discovery\\n\\nfor past months tracking warren buffett holdings\\n\\nand found surprising tesla expected deliver model vehicles model s model x according word factset tesla announced sound approximate defeats fronts noting shipped model vehicles model s model x vehicles wiggle room defeat quotewhy shipped putting bloc unclearit mean win category example model x sales faltered got door mean shipped model s units better overestimates additionally production numbers tesla looking sharp company setting production records quarter actually delivering cars produced company clear focus production putting largely rest concerns tesla total manufacturing capability leave niche product tesla continues build charge good numbers tesla lately buzz better christmas saw wedbush securities hike price target share meeting price target require substantial drop current share price weeks wind predictions credit suisse analyst dan levy suggesting potential percent drop stock price come based appearance extra competition fieldand line ford nyse f recently noted reservations upcoming mache electric mustang fullthe production delivery numbers emerging tesla suggests position effectively competition doubt tesla gaining lot ground lately beaten short sellers notable occasion bull cases suggesting stock room run current levels idea tesla stymied push electric vehicles market flawed best tesla having unexpected advantages arsenal like rapid improvements battery technology possibility company diversify couple extra revenue streams point seldom goes amiss face increased competition people interested electric vehicles right tesla leading way provision competition likely followthese figures substantial suggest want piece piebut diversification potential hand tesla able hold levels ardent bulls right oil stocks survive current crisis think longterm prospects business paid buy products oversimplification occurred futures contract oil april price contract sold negative price time history\\n\\nthe crisis befalling oil companies time best described strongest survive way oil companies possibly handle month month rockbottom oil prices\\n\\nthe problem comically simple understand massively reduced demand oil millions americans following mitigation orders ranging social distancing guidelines restrictive shelter place orders time market trying absorb oversupply oil came russia saudi arabia\\n\\nhowever year started things looked like business usual oil producers yous economy humming talk second half year finally bring boost oil prices companies badly needed\\n\\nhowever middle february dropped market general oil prices main sectors feel impact\\n\\ninitially investors tried remain optimistic month ago investors thought economy reopening sooner later exact timing reopening fluid barrel oil looking likely demand destruction little prop stock oil companies\\n\\nand means likelihood room left oil companies highlighted oil stocks strong probability surviving chaos surrounding coronavirus nation response view oil stocks survive current crisis complete form receive latest headlines analysts recommendations stocks free daily email newsletter'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_stopwords(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf89d7a6",
   "metadata": {},
   "source": [
    "### Combined Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f75fc43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocessing(df):\n",
    "    df = df.copy()\n",
    "    df['content_processed'] = ''\n",
    "    col_index = df.columns.get_loc('content_processed')\n",
    "        \n",
    "    for idx, content in tqdm(enumerate(df['content'])):\n",
    "        #print(idx)\n",
    "        #print(idx, 'content: \\n',content, '\\n')\n",
    "        text = strip_text(content)\n",
    "        text = remove_numbers(text)\n",
    "        #print('numbers: \\n', text, '\\n')\n",
    "        text = remove_emails_tags(text)\n",
    "        #print('emails: \\n',text, '\\n')\n",
    "        text = expand_contractions(text)\n",
    "        text = remove_contraction_possesive_apostrophes(text)\n",
    "        text = remove_accents_non_english_char(text)\n",
    "        text = remove_punctuation(text)\n",
    "        text = remove_numbers(text)\n",
    "        text = remove_long_words(text)\n",
    "        text = lowercase_text(text)\n",
    "        text = remove_stopwords(text)\n",
    "\n",
    "        df.iat[idx, col_index] = text\n",
    "        #if idx % 50000 == 0:\n",
    "         #   print(f'{idx} records processed')\n",
    "    \n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253df704",
   "metadata": {},
   "source": [
    "# Complete Preprocessing - Step 1 - Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bfdf8fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_preprocessing = False\n",
    "\n",
    "if complete_preprocessing:\n",
    "    # ~ 30 mins to run\n",
    "    df_processed = drop_articles(df)\n",
    "    df_processed = data_preprocessing(df_processed)\n",
    "    df_processed.to_pickle('./data/df_processed.pickle')\n",
    "else:\n",
    "    df_processed = pd.read_pickle('./data/df_processed.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c4d838e4-5df8-4945-9fce-6a3d06d70cda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "365200\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>date</th>\n",
       "      <th>domain</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>content</th>\n",
       "      <th>topic_area</th>\n",
       "      <th>content_processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Thomas Hughes</td>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>marketbeat</td>\n",
       "      <td>Three Industrial Giants You Should Own In 2020</td>\n",
       "      <td>https://www.marketbeat.com/originals/three-ind...</td>\n",
       "      <td>With the end of the year just around the corne...</td>\n",
       "      <td>business</td>\n",
       "      <td>end year corner past time think positioning fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369046</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>marketscreener</td>\n",
       "      <td>FTSE 100 wraps up worst year since 2008 financ...</td>\n",
       "      <td>https://www.marketscreener.com/quote/index/FTS...</td>\n",
       "      <td>The FTSE 100 lost 1.5%, with consumer stocks, ...</td>\n",
       "      <td>business</td>\n",
       "      <td>ftse lost consumer stocks mainly unilever diag...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               author       date          domain  \\\n",
       "0       Thomas Hughes 2020-01-02      marketbeat   \n",
       "369046            NaN 2020-12-31  marketscreener   \n",
       "\n",
       "                                                    title  \\\n",
       "0          Three Industrial Giants You Should Own In 2020   \n",
       "369046  FTSE 100 wraps up worst year since 2008 financ...   \n",
       "\n",
       "                                                      url  \\\n",
       "0       https://www.marketbeat.com/originals/three-ind...   \n",
       "369046  https://www.marketscreener.com/quote/index/FTS...   \n",
       "\n",
       "                                                  content topic_area  \\\n",
       "0       With the end of the year just around the corne...   business   \n",
       "369046  The FTSE 100 lost 1.5%, with consumer stocks, ...   business   \n",
       "\n",
       "                                        content_processed  \n",
       "0       end year corner past time think positioning fo...  \n",
       "369046  ftse lost consumer stocks mainly unilever diag...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(df_processed))\n",
    "df_processed.head(1).append(df_processed.tail(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1092f19e-5e27-4da9-9959-950272668c0a",
   "metadata": {},
   "source": [
    "## Colocations\n",
    "\n",
    "Process:\n",
    "* find collocations\n",
    "* determine cutoff (at least 50 times present, top 1000 bigrams?)\n",
    "* search all text and combine bigrams into one word with _ seperator e.g. supply_chain\n",
    "\n",
    "TO DO\n",
    "* When converting bigrams, convert highest ranking bigrams first, e.g. a problem is president_donald and donald_trump are both found colocations, but my converting process takes the first words found and so while donald_trump is a better bigram, president_donald is the one that is formed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d5dde2a-aa91-44d6-94ca-bdc5596b9baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "#nltk.download('punkt')\n",
    "from nltk.collocations import *\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f5496c61-709b-484d-83b7-ea7d0afe3291",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenise_dataframe(df):\n",
    "\n",
    "    df = df.copy()\n",
    "    df['tokens'] = \"\"\n",
    "    col_index = df.columns.get_loc(\"tokens\")\n",
    "    \n",
    "    for idx, article in enumerate(df['content_processed']):\n",
    "        tokens = word_tokenize(article)\n",
    "        df.iat[idx, col_index] = list(tokens)\n",
    "    \n",
    "    return df\n",
    "    \n",
    "def find_colocations(tokens, min_freq=1000, n_bigrams=2000):\n",
    "    \n",
    "    bigram_measures = nltk.collocations.BigramAssocMeasures()\n",
    "    #trigram_measures = nltk.collocations.TrigramAssocMeasures()\n",
    "    \n",
    "    #finder_bigram = BigramCollocationFinder.from_words(tokens)\n",
    "    #finder_trigram = TrigramCollocationFinder.from_words(tokens)\n",
    "\n",
    "    finder_bigram = BigramCollocationFinder.from_documents(tokens)\n",
    "    #finder_trigram = TrigramCollocationFinder.from_documents(tokens)\n",
    "    \n",
    "    finder_bigram.apply_freq_filter(min_freq) # minimum number of occurances to be included\n",
    "    bigrams = finder_bigram.nbest(bigram_measures.pmi, n_bigrams)\n",
    "    df_bigrams_freq = pd.DataFrame(finder_bigram.ngram_fd.items(), columns=['bigram', 'freq'])\n",
    "\n",
    "    return bigrams, df_bigrams_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "547e8e95-bc34-4036-8799-ebcf7526a286",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_token = tokenise_dataframe(df_processed[:1000])\n",
    "test_bigrams, test_df_bigrams_freq = find_colocations(test_token['tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c19a6367-de68-46ea-851f-177724fb5a1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_bigrams[:5]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bc198769-e7df-4fc4-b50a-6495b3e6f50d",
   "metadata": {},
   "source": [
    "print(('supply', 'chain') in test_bigrams)\n",
    "print(test_bigrams.index(('supply', 'chain')))\n",
    "test_bigrams.index(('supply', 'chains'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "943bfdd6-02fd-42f9-a48a-706e4da0f313",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bigrams_article(text, bigrams):\n",
    "    \"\"\"\n",
    "    :convert bigrams to one word for an individual article\n",
    "    used within create_bigrams function\n",
    "    \"\"\"\n",
    "\n",
    "    tokens = text.split(\" \")\n",
    "    tokens_with_bigrams = []\n",
    "    idx = 0\n",
    "    while idx < len(tokens) -1:\n",
    "        if (tokens[idx], tokens[idx+1]) in bigrams:\n",
    "            bigram = str(tokens[idx]) + '_' + str(tokens[idx+1])\n",
    "            tokens_with_bigrams.append(bigram)\n",
    "            idx += 2\n",
    "        else:\n",
    "            tokens_with_bigrams.append(tokens[idx])\n",
    "            idx += 1\n",
    "    if (tokens[-2], tokens[-1]) not in bigrams:\n",
    "        tokens_with_bigrams.append(tokens[-1])\n",
    "\n",
    "    text_clean = (\" \").join(tokens_with_bigrams)\n",
    "    \n",
    "    return text_clean\n",
    "        \n",
    "def create_bigrams(df, min_freq=1000, n_bigrams=2000):\n",
    "    \"\"\"\n",
    "    :convert bigrams to one word for entire df\n",
    "    \"\"\"\n",
    "    \n",
    "    df = df.copy()\n",
    "    col_index = df.columns.get_loc('content_processed')\n",
    "    \n",
    "    df_tokenised = tokenise_dataframe(df)\n",
    "    print('df tokenised')\n",
    "    tokens = df_tokenised['tokens']\n",
    "    \n",
    "    bigrams, df_bigrams_freq = find_colocations(tokens, min_freq, n_bigrams)\n",
    "    print('bigrams found')\n",
    "            \n",
    "    for idx, content in tqdm(enumerate(df['content_processed'])):\n",
    "        text = create_bigrams_article(content, bigrams)\n",
    "        df.iat[idx, col_index] = text\n",
    "        #if idx % 50000 == 0:\n",
    "         #   print(f'{idx} records processed')\n",
    "            \n",
    "    return bigrams, df, df_bigrams_freq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb25d1ad-4c4f-4f9e-86b8-d0f8b73035a6",
   "metadata": {},
   "source": [
    "# Complete Preprocessing - Step 2 - Colocations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143d110b-b34a-4b3f-8389-c5db4a871a3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df tokenised\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:00, 28.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bigrams found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "254213it [1:46:58, 47.21it/s]"
     ]
    }
   ],
   "source": [
    "complete_preprocessing = True\n",
    "\n",
    "if complete_preprocessing:\n",
    "    # ~ 1 hours to run\n",
    "    df_processed = pd.read_pickle('./data/df_processed.pickle')\n",
    "    bigrams, df_processed_bigrams, df_bigrams_freq = create_bigrams(df_processed)\n",
    "    df_processed_bigrams.to_pickle('./data/df_processed_bigrams.pickle')\n",
    "    \n",
    "    df_bigrams = pd.DataFrame(bigrams, columns=['bigram_w1', 'bigram_w2'])\n",
    "    df_bigrams['freq'] = ''\n",
    "    for idx in range(len(df_bigrams)):\n",
    "        bigram_check = (df_bigrams['bigram_w1'][idx], df_bigrams['bigram_w2'][idx])\n",
    "        freq = df_bigrams_freq[df_bigrams_freq['bigram'] == bigram_check]['freq'].values[0]\n",
    "        df_bigrams.loc[idx, 'freq'] = freq\n",
    "    df_bigrams.to_csv('./data/bigrams.csv', index=False)\n",
    "    df_bigrams_freq.to_csv('./data/df_bigrams_freq.csv', index=False)\n",
    "    \n",
    "else:\n",
    "    df_processed_bigrams = pd.read_pickle('./data/df_processed_bigrams.pickle')\n",
    "    df_bigrams = pd.read_csv('./data/bigrams.csv')\n",
    "    df_bigrams_freq = pd.read_csv('./data/df_bigrams_freq.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "24febccb-ce75-4668-969f-cf46deb90f12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bigram</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(end, year)</td>\n",
       "      <td>13015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(time, think)</td>\n",
       "      <td>1301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(market, leader)</td>\n",
       "      <td>1328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(energy, sector)</td>\n",
       "      <td>1788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(expected, grow)</td>\n",
       "      <td>2722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8596</th>\n",
       "      <td>(15year, perspective)</td>\n",
       "      <td>2571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8597</th>\n",
       "      <td>(presidentelect, joe)</td>\n",
       "      <td>1877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8598</th>\n",
       "      <td>(content, december)</td>\n",
       "      <td>1172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8599</th>\n",
       "      <td>(unaltered, december)</td>\n",
       "      <td>1232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8600</th>\n",
       "      <td>(december, utc)</td>\n",
       "      <td>1232</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8589 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     bigram   freq\n",
       "0               (end, year)  13015\n",
       "1             (time, think)   1301\n",
       "2          (market, leader)   1328\n",
       "3          (energy, sector)   1788\n",
       "4          (expected, grow)   2722\n",
       "...                     ...    ...\n",
       "8596  (15year, perspective)   2571\n",
       "8597  (presidentelect, joe)   1877\n",
       "8598    (content, december)   1172\n",
       "8599  (unaltered, december)   1232\n",
       "8600        (december, utc)   1232\n",
       "\n",
       "[8589 rows x 2 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bigrams_freq[df_bigrams_freq['freq'] < 50000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1b052a21-1eff-4d4f-ab0a-5a09b40beed9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bigram</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>(supply, chains)</td>\n",
       "      <td>9493</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               bigram  freq\n",
       "137  (supply, chains)  9493"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bigrams_freq[df_bigrams_freq['bigram'] == ('supply', 'chains')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1c499e3d-9d79-4f2e-84e9-502333ddfbc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#df_bigrams_freq['freq'].hist()\n",
    "df_bigrams_freq[df_bigrams_freq['freq'] < 5000]['freq'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba6fba04-60b1-48dd-b2cf-db9b702e01ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "365200\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>date</th>\n",
       "      <th>domain</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>content</th>\n",
       "      <th>topic_area</th>\n",
       "      <th>content_processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Thomas Hughes</td>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>marketbeat</td>\n",
       "      <td>Three Industrial Giants You Should Own In 2020</td>\n",
       "      <td>https://www.marketbeat.com/originals/three-ind...</td>\n",
       "      <td>With the end of the year just around the corne...</td>\n",
       "      <td>business</td>\n",
       "      <td>end year corner past time think positioning fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369046</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>marketscreener</td>\n",
       "      <td>FTSE 100 wraps up worst year since 2008 financ...</td>\n",
       "      <td>https://www.marketscreener.com/quote/index/FTS...</td>\n",
       "      <td>The FTSE 100 lost 1.5%, with consumer stocks, ...</td>\n",
       "      <td>business</td>\n",
       "      <td>ftse lost consumer stocks mainly unilever diag...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               author       date          domain  \\\n",
       "0       Thomas Hughes 2020-01-02      marketbeat   \n",
       "369046            NaN 2020-12-31  marketscreener   \n",
       "\n",
       "                                                    title  \\\n",
       "0          Three Industrial Giants You Should Own In 2020   \n",
       "369046  FTSE 100 wraps up worst year since 2008 financ...   \n",
       "\n",
       "                                                      url  \\\n",
       "0       https://www.marketbeat.com/originals/three-ind...   \n",
       "369046  https://www.marketscreener.com/quote/index/FTS...   \n",
       "\n",
       "                                                  content topic_area  \\\n",
       "0       With the end of the year just around the corne...   business   \n",
       "369046  The FTSE 100 lost 1.5%, with consumer stocks, ...   business   \n",
       "\n",
       "                                        content_processed  \n",
       "0       end year corner past time think positioning fo...  \n",
       "369046  ftse lost consumer stocks mainly unilever diag...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(df_processed_bigrams))\n",
    "df_processed_bigrams.head(1).append(df_processed_bigrams.tail(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3385aced-fb0b-4fdf-bd24-a704b70423b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bigram_w1</th>\n",
       "      <th>bigram_w2</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>thermo</td>\n",
       "      <td>fisher</td>\n",
       "      <td>1204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>fiat</td>\n",
       "      <td>chrysler</td>\n",
       "      <td>2061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>hk000</td>\n",
       "      <td>hk000</td>\n",
       "      <td>1156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>navigator</td>\n",
       "      <td>evaluates</td>\n",
       "      <td>1025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>timo</td>\n",
       "      <td>werner</td>\n",
       "      <td>1145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>thread</td>\n",
       "      <td>preparatory</td>\n",
       "      <td>1484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>jacinda</td>\n",
       "      <td>ardern</td>\n",
       "      <td>1166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>jurgen</td>\n",
       "      <td>klopp</td>\n",
       "      <td>1636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>tedros</td>\n",
       "      <td>adhanom</td>\n",
       "      <td>1979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>borussia</td>\n",
       "      <td>dortmund</td>\n",
       "      <td>1654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>stuffy</td>\n",
       "      <td>sinuses</td>\n",
       "      <td>3441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>leslie</td>\n",
       "      <td>adler</td>\n",
       "      <td>1085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>narendra</td>\n",
       "      <td>modi</td>\n",
       "      <td>1614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>shinzo</td>\n",
       "      <td>abe</td>\n",
       "      <td>1291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>eli</td>\n",
       "      <td>lilly</td>\n",
       "      <td>1437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>ihs</td>\n",
       "      <td>markit</td>\n",
       "      <td>3029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>asylum</td>\n",
       "      <td>seekers</td>\n",
       "      <td>1004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>seatbelt</td>\n",
       "      <td>buckle</td>\n",
       "      <td>3443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>noses</td>\n",
       "      <td>stuffy</td>\n",
       "      <td>3442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>thermometer</td>\n",
       "      <td>pricey</td>\n",
       "      <td>3003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      bigram_w1    bigram_w2  freq\n",
       "20       thermo       fisher  1204\n",
       "21         fiat     chrysler  2061\n",
       "22        hk000        hk000  1156\n",
       "23    navigator    evaluates  1025\n",
       "24         timo       werner  1145\n",
       "25       thread  preparatory  1484\n",
       "26      jacinda       ardern  1166\n",
       "27       jurgen        klopp  1636\n",
       "28       tedros      adhanom  1979\n",
       "29     borussia     dortmund  1654\n",
       "30       stuffy      sinuses  3441\n",
       "31       leslie        adler  1085\n",
       "32     narendra         modi  1614\n",
       "33       shinzo          abe  1291\n",
       "34          eli        lilly  1437\n",
       "35          ihs       markit  3029\n",
       "36       asylum      seekers  1004\n",
       "37     seatbelt       buckle  3443\n",
       "38        noses       stuffy  3442\n",
       "39  thermometer       pricey  3003"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bigrams[20:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "a387a6b0-40db-4c03-ad63-0afa4d164cee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bigram_w1</th>\n",
       "      <th>bigram_w2</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>960</th>\n",
       "      <td>supply</td>\n",
       "      <td>chains</td>\n",
       "      <td>9490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>supply</td>\n",
       "      <td>chain</td>\n",
       "      <td>23584</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    bigram_w1 bigram_w2   freq\n",
       "960    supply    chains   9490\n",
       "992    supply     chain  23584"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bigrams[df_bigrams['bigram_w1'] == 'supply']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "c749aef0-02d9-41f9-9f1c-f9ae7d92b476",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bigram_w1</th>\n",
       "      <th>bigram_w2</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [bigram_w1, bigram_w2, freq]\n",
       "Index: []"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bigrams[df_bigrams['freq'] <= 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "56c9a851-d83b-4701-a910-2ac658eeb458",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bigram_w1</th>\n",
       "      <th>bigram_w2</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1476</th>\n",
       "      <td>mapelli</td>\n",
       "      <td>mozzi</td>\n",
       "      <td>719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1541</th>\n",
       "      <td>marguerita</td>\n",
       "      <td>choy</td>\n",
       "      <td>773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1559</th>\n",
       "      <td>oyu</td>\n",
       "      <td>tolgoi</td>\n",
       "      <td>742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1594</th>\n",
       "      <td>anglogold</td>\n",
       "      <td>ashanti</td>\n",
       "      <td>733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1612</th>\n",
       "      <td>buenos</td>\n",
       "      <td>aires</td>\n",
       "      <td>768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1700</th>\n",
       "      <td>shounak</td>\n",
       "      <td>dasgupta</td>\n",
       "      <td>872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1756</th>\n",
       "      <td>estados</td>\n",
       "      <td>unidos</td>\n",
       "      <td>794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1782</th>\n",
       "      <td>tamil</td>\n",
       "      <td>nadu</td>\n",
       "      <td>866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1829</th>\n",
       "      <td>arun</td>\n",
       "      <td>koyyur</td>\n",
       "      <td>749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1881</th>\n",
       "      <td>shri</td>\n",
       "      <td>navaratnam</td>\n",
       "      <td>801</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       bigram_w1   bigram_w2 freq\n",
       "1476     mapelli       mozzi  719\n",
       "1541  marguerita        choy  773\n",
       "1559         oyu      tolgoi  742\n",
       "1594   anglogold     ashanti  733\n",
       "1612      buenos       aires  768\n",
       "1700     shounak    dasgupta  872\n",
       "1756     estados      unidos  794\n",
       "1782       tamil        nadu  866\n",
       "1829        arun      koyyur  749\n",
       "1881        shri  navaratnam  801"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bigrams[(df_bigrams['freq'] >= 700) & (df_bigrams['freq'] <= 1000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "175ef878-0ec7-4d39-b708-2b971ae4e7e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bigram_w1</th>\n",
       "      <th>bigram_w2</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [bigram_w1, bigram_w2, freq]\n",
       "Index: []"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bigrams[df_bigrams['bigram_w1'] == 'supply']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "cd275643-d05d-4651-abb7-88d6f60435a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bigram</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(end, year)</td>\n",
       "      <td>13003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(time, think)</td>\n",
       "      <td>1193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(market, leader)</td>\n",
       "      <td>1326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(energy, sector)</td>\n",
       "      <td>1784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(expected, grow)</td>\n",
       "      <td>2718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9074</th>\n",
       "      <td>(15year, perspective)</td>\n",
       "      <td>2571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9075</th>\n",
       "      <td>(presidentelect, joe)</td>\n",
       "      <td>1875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9076</th>\n",
       "      <td>(content, december)</td>\n",
       "      <td>1172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9077</th>\n",
       "      <td>(unaltered, december)</td>\n",
       "      <td>1232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9078</th>\n",
       "      <td>(december, utc)</td>\n",
       "      <td>1232</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9079 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     bigram   freq\n",
       "0               (end, year)  13003\n",
       "1             (time, think)   1193\n",
       "2          (market, leader)   1326\n",
       "3          (energy, sector)   1784\n",
       "4          (expected, grow)   2718\n",
       "...                     ...    ...\n",
       "9074  (15year, perspective)   2571\n",
       "9075  (presidentelect, joe)   1875\n",
       "9076    (content, december)   1172\n",
       "9077  (unaltered, december)   1232\n",
       "9078        (december, utc)   1232\n",
       "\n",
       "[9079 rows x 2 columns]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bigrams_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "90818fac-2e0b-42f1-b960-c80c27f4ca26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bigram</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>(supply, chain)</td>\n",
       "      <td>23584</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              bigram   freq\n",
       "438  (supply, chain)  23584"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bigrams_freq[df_bigrams_freq['bigram'] == ('supply', 'chain')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac2a5c8",
   "metadata": {},
   "source": [
    "### Strip company names out of text\n",
    "Just an idea to come back to because otherwise they may form significance for topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "7b82beb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With the end of the year just around the corner, it’s past time to think about positioning for2020. When it comes to earnings power in 2020, the Industrial sector is going to be the market leader and that is where I like my money to be. To be clear, when I say Industrial Sector I mean the S&P 500 Industrial Sector as represented by the ETF (XLI). Yes, the Energy Sector is expected to post EPS growth double that of the Industrials but investors should take that news with a grain of salt. The Energy Sector’s (XLE) consensus EPS growth estimate for 2020 is 21% but only after falling -28% this year. The Industrial Sector is expected to grow by 15% next year (2nd fastest pace for the S&P 500) after contracting only -3% this year. That means the Energy Sector’s earnings will still be down on a two-year basis while the Industrial’s will rise. Energy may yet turn out to be a good investment for 2020 but, on an earnings basis, the Industrials are a much better choice. Don’t Bet On Boeing Boeing (BA) is by far the largest holding within the Industrial Sector SPDR but not an investment I recommend at this time. At just over 8% it outweighs the #2 holding, Honeywell (HON), by nearly 200 basis points and that is why the XLI is not the best choice for investors today. With the 737-Max scandal still raging it is unlikely Boeing will back in 2020. The most recent news on that front is the ousting of CEO Dennis Muilenberg. Muilenberg has been in charge of Boeing since 2015 and key to the 737-Max crisis, the board decided it was in the company’s best interest to find someone else. document.write('<a style=\"text-decoration:none;font-weight:normal;color:#696969;\" target=\"_blank\" rel=\"nofollow\" href=\"https://www.ame' + 'ricanconsumernews.net/scripts/click.aspx?NativeDisplayAdID=584&ImpressionID=0&UserID=0&Placement=PlaceOnArticlePage\">');Buffett is notoriously “anti technology.” Which is why this Wall Street Legend's recent discover is so shocking:\n",
      "21 of Buffett’s 25 current favorite companies are going “all in” one hot new technology… To the tune of $1.7 billion! ...After decades of being anti-tech...what is making Buffett going all in now? And what is this new technology that America's biggest companies are in a race to implement? There are several stocks within the XLI portfolio on the move and looking bullish. The three I want to highlight today are uniquely set up for 2020 and we can give thanks to the trade war for that. Caterpillar (CAT), Deere & Company (DE), and Cummins Inc (CMI) have all seen their business deteriorate due to the trade war issuing downgrades and missing estimates. Now, with the Phase One Deal in sight, that is all about to change. Once the deal is signed and the details are well known we can expect to see a flurry of analysts upgrades for these stocks and this sector. Cummins Inc, On The Move Cummins Inc is a maker of engines and components for heavy industrial trucks. The company has been suffering due to softening demands for those trucks but you wouldn’t think so looking at the share price. The price of Cummins has risen nearly 30% since hitting a bottom last August and looks ready to continue rising in 2020. The outlook for growth, and the impact of the Phase One Deal on that outlook, are only part of the reason Cummins is on the move. Cummins is also a solid dividend payer and a prolific buyer of its own stock so a great way to capitalize on this industry. At today’s prices, the stock yields close to 3% and has a 14-year  history of distribution increases. The XLI only pays aobut 1.9%. As for buybacks, the board just announced another $2 billion in buybacks slated for 2020. Deere & Company, China Is The Key To Growth Deere & Company, that iconic maker of tractors, recently downgraded its outlook for 2020 due to the trade war. The company says lingering trade tensions played a big roll in the decision which makes the Phase One Deal of particular importance. The idea is that, once the Phase One Deal is signed, trade with China will reinvigorate growth globally, not just in the China segment of the business. Looking at the earnings picture, Deere & Company will be one of 2020’s best EPS growers despite the recent downgrade to guidance. The consensus estimate for EPS is $11.02, a 27% increase from 2019. Like Cummins, Deere & Company is a dividend payer and an attractive one at that. The yield is a little low, only 1.75% at today’s prices, but it is a safe 1.75%. The payout ratio is only 27% of next year’s earnings which also leaves plenty of room for an increase. Caterpillar, A Dividend Aristocrat For Capital Gains In 2020 Shares of Caterpillar have been on the move in the second half of 2019 too. The stock is up more than 31% in the last four months and may easily match that gain in 2020. While the business has been struggling this year, the impact of tariffs has not been as great as feared. In addition, Caterpillar’s CEO says many of its businesses have “significant potential upside.” On a technical basis, the stock is forming a Bullish Flag Pattern with a $36 flag-pole. If, when, the pattern confirms traders can expect the stock to rise as much as or more than $36. Such a move would put the stock at a new all-time high. Regarding the dividend, Caterpillar is a Dividend Aristocrat with 26 years of distribution increases under its belt. The yield at today's prices is about 2.8% with a low 38% payout ratio. 6 Stocks That Will Benefit From a Dovish Federal Reserve The quaint correction that was labeled the “tech wreck” of 2018 seems like a distant memory to investors. What also seems like a distant memory is any thought of the Federal Reserve raising interest rates.\n",
      "\n",
      "At the end of 2018, the Federal Reserve had raised its benchmark federal funds rate. With the trade dispute with China dragging on, there was increasing pressure on the Fed to lower interest rates. When interest rates are lower, stocks will generally rise as investors have no other option for growth.\n",
      "\n",
      "In July 2019, the doves got their wish. But in a move that now seems to be a “what did they know move”, the Fed dropped rates again in October. The market soared to record highs in January and early February. Since mid-February however, the market has fallen dramatically, and the Fed juiced the market one more time by cutting rates down to levels not seen since the financial crisis.\n",
      "\n",
      "None of us know for sure when the U.S. economy will be opened up. And while stocks are still a good investment, not every stock is a smart investment at this time. But some stocks perform well when interest rates are falling and that’s why we’ve prepared this presentation.\n",
      "\n",
      "These six stocks stand to benefit from both low-interest rates and the unique economic conditions being brought on by the Covid-19 pandemic. View the \"6 Stocks That Will Benefit From a Dovish Federal Reserve\". Complete the form below to receive the latest headlines and analysts' recommendations for your stocks with our free daily email newsletter:\n"
     ]
    }
   ],
   "source": [
    "print(df['content'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af18943",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
