{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "419c18d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import regex as re\n",
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from spacy.lang.en import English\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "035af083",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n",
      "GPUs:  0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['TF_XLA_FLAGS'] = '--tf_xla_enable_xla_devices'\n",
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "print(\"GPUs: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f847e73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. articles dropped:  127\n",
      "no. of articles:  368920\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('./Data/covid19_articles_20201231.csv')\n",
    "\n",
    "# Date to datetime\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "# Drop duplicates\n",
    "num_articles_pre_drop = len(df)\n",
    "df = df.drop_duplicates(subset='content')\n",
    "df = df.reset_index(drop=True)\n",
    "print('no. articles dropped: ', num_articles_pre_drop - len(df))\n",
    "print('no. of articles: ', len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09ffd888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. articles dropped:  801\n",
      "no. of articles:  368119\n"
     ]
    }
   ],
   "source": [
    "# Drop long articles\n",
    "num_articles_pre_drop = len(df)\n",
    "df = df[df['content'].str.len() < 100000].reset_index(drop=True)\n",
    "print('no. articles dropped: ', num_articles_pre_drop - len(df))\n",
    "print('no. of articles: ', len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29ed72e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. articles dropped:  172\n",
      "no. of articles:  367947\n"
     ]
    }
   ],
   "source": [
    "# Drop articles with annual report as title\n",
    "num_articles_pre_drop = len(df)\n",
    "df = df[~df['title'].str.contains(\"Annual Report\", na=False)].reset_index(drop=True)\n",
    "print('no. articles dropped: ', num_articles_pre_drop - len(df))\n",
    "print('no. of articles: ', len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1aecec45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>date</th>\n",
       "      <th>domain</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>content</th>\n",
       "      <th>topic_area</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Thomas Hughes</td>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>marketbeat</td>\n",
       "      <td>Three Industrial Giants You Should Own In 2020</td>\n",
       "      <td>https://www.marketbeat.com/originals/three-ind...</td>\n",
       "      <td>With the end of the year just around the corne...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Thomas Hughes</td>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>marketbeat</td>\n",
       "      <td>Labor Stocks Are Going To Break Out In 2020</td>\n",
       "      <td>https://www.marketbeat.com/originals/labor-sto...</td>\n",
       "      <td>The labor markets were one of the most closely...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Steve Anderson</td>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>marketbeat</td>\n",
       "      <td>Tesla (TSLA) Breaks Shipment Record, Beats Est...</td>\n",
       "      <td>https://www.marketbeat.com/originals/teal-brea...</td>\n",
       "      <td>It could be forgiven, that some might think th...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            author       date      domain  \\\n",
       "0    Thomas Hughes 2020-01-02  marketbeat   \n",
       "1    Thomas Hughes 2020-01-03  marketbeat   \n",
       "2  Steve Anderson  2020-01-03  marketbeat   \n",
       "\n",
       "                                               title  \\\n",
       "0     Three Industrial Giants You Should Own In 2020   \n",
       "1        Labor Stocks Are Going To Break Out In 2020   \n",
       "2  Tesla (TSLA) Breaks Shipment Record, Beats Est...   \n",
       "\n",
       "                                                 url  \\\n",
       "0  https://www.marketbeat.com/originals/three-ind...   \n",
       "1  https://www.marketbeat.com/originals/labor-sto...   \n",
       "2  https://www.marketbeat.com/originals/teal-brea...   \n",
       "\n",
       "                                             content topic_area  \n",
       "0  With the end of the year just around the corne...   business  \n",
       "1  The labor markets were one of the most closely...   business  \n",
       "2  It could be forgiven, that some might think th...   business  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f34333e",
   "metadata": {},
   "source": [
    "### Cleaning Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d263e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_emails_tags(text):\n",
    "    \"\"\"\n",
    "    : remove emails and tags (e.g @sleepingbeauty)\n",
    "    \"\"\"\n",
    "    # Add a space before commas to seperate from preceeding word\n",
    "    text = re.sub(\",\", \" ,\", text)\n",
    "    \n",
    "    regex_email = re.compile(r'[\\w\\.-]+@[\\w\\.-]+.') # email with character at end, e.g. space\n",
    "    regex_email2 = re.compile(r'[\\w\\.-]+@[\\w\\.-]+') # email with no character at end\n",
    "    regex_tag = re.compile(r'@[\\w\\.-]+') # tags e.g @sleepingbeauty\n",
    "    regex_tag = re.compile(r'\\S+@[\\w\\.-]+.') # tags plust character e.g (@sleepingbeauty)\n",
    "    email = regex_email.findall(text)\n",
    "    email2 = regex_email2.findall(text)\n",
    "    tag = regex_tag.findall(text)\n",
    "    word_removals = email + email2 + tag\n",
    "    \n",
    "    tokens = text.split(\" \")\n",
    "    # Remove if email\n",
    "    tokens_filtered = [word for word in tokens if word not in word_removals]\n",
    "    \n",
    "    text_clean = (\" \").join(tokens_filtered)\n",
    "    \n",
    "    return text_clean\n",
    "\n",
    "\n",
    "def is_number(text):\n",
    "    \"\"\"\n",
    "    :utility function to test if text is a number\n",
    "    \"\"\"\n",
    "    try:\n",
    "        float(text) if '.' in text else int(text)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "def remove_numbers(text):\n",
    "    \"\"\"\n",
    "    :remove numbers, percentages, dollar values\n",
    "    \"\"\"\n",
    "    \n",
    "    regex_percent = re.compile(r'[\\-\\+]?[\\d]+\\.?\\d*[%]+\\.?') # e.g. 3%, -3.8%\n",
    "    regex_number_fullstop = re.compile(r'\\d+[\\.]') # e.g. 2019.\n",
    "    regex_dollar_number = re.compile(r'[\\$]+[\\d,]+\\.?\\d*') # e.g. $2 or $2.4567\n",
    "    \n",
    "    percent = regex_percent.findall(text)\n",
    "    number_fullstop = regex_number_fullstop.findall(text)\n",
    "    dollar_number = regex_dollar_number.findall(text)\n",
    "    word_removals = percent + number_fullstop + dollar_number\n",
    "\n",
    "    tokens = text.split(\" \")\n",
    "    \n",
    "    # remove integers and floats\n",
    "    tokens_filtered = [word for word in tokens if not is_number(word)]\n",
    "    # remove percentages\n",
    "    tokens_filtered = [word for word in tokens_filtered if word not in word_removals]\n",
    "    \n",
    "    text_clean = (\" \").join(tokens_filtered)\n",
    "    \n",
    "    return text_clean\n",
    "\n",
    "def remove_contraction_possesive_apostrophes(text):\n",
    "    \"\"\"\n",
    "    :remove contraction e.g. can't, won't, she'll -> cant, and possesive apostrophes +s e.g The president's dog -> president\n",
    "    note: not completely correct as removes 's from e.g. that's which is a contraction rather that possessive, but this is not seen as an issue\n",
    "    \"\"\"\n",
    "    \n",
    "    regex_contraction = re.compile(r\"[a-zA-Z]+'[a-rt-zA-RT-Z]+|[a-zA-Z]+’[a-rt-zA-RT-Z]+\")\n",
    "    contraction = regex_contraction.findall(text)\n",
    "    \n",
    "    regex_possessive = re.compile(r\"[a-zA-Z]+'[sS]+|[a-zA-Z]+’[sS]+\")\n",
    "    possessive = regex_possessive.findall(text)\n",
    "    \n",
    "    tokens = text.split(\" \")\n",
    "    \n",
    "    # remove contractions\n",
    "    tokens_filtered = [word if word not in contraction else word.replace(\"'\", \"\").replace(\"’\",\"\") for word in tokens]\n",
    "    # replace 's\n",
    "    tokens_filtered = [word if word not in possessive else word.replace(\"'s\", \"\").replace(\"’s\",\"\").replace(\"'S\",\"\").replace(\"’S\",\"\") for word in tokens_filtered]\n",
    "    \n",
    "    text_clean = (\" \").join(tokens_filtered)\n",
    "    \n",
    "    return text_clean\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac9c0947",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = remove_emails_tags(df['content'][2])\n",
    "test = remove_contraction_possesive_apostrophes(test)\n",
    "#test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4693770c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sentences(text):\n",
    "    \"\"\"\n",
    "    return a list of sentences from text based on common separators\n",
    "    \"\"\"\n",
    "    sentence_delimiters = re.compile(u'[.!?,;:\\t\\\\\\\\\"\\\\(\\\\)\\\\\\'\\u2019\\u2013]|\\\\s\\\\-\\\\s')\n",
    "    sentences = sentence_delimiters.split(text)\n",
    "    \n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a38c613",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = split_sentences(test)\n",
    "#test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5961e809",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_stop_word_regex():\n",
    "    \"\"\"\n",
    "    :used in function generate_phrases to remove stopwords before\n",
    "    compiling multi word phrases\n",
    "    \"\"\"\n",
    "    stop_word_list = spacy.lang.en.stop_words.STOP_WORDS\n",
    "    stop_word_regex_list = []\n",
    "    for word in stop_word_list:\n",
    "        word_regex = r'\\b' + word + r'(?![\\w-])'\n",
    "        stop_word_regex_list.append(word_regex)\n",
    "    stop_word_pattern = re.compile('|'.join(stop_word_regex_list), re.IGNORECASE)\n",
    "    return stop_word_pattern\n",
    "\n",
    "def generate_phrases(text, stopword_regex):\n",
    "    \"\"\"\n",
    "    :compile list of multi word phrases by splitting sentences on stopwords\n",
    "    \"\"\"\n",
    "    \n",
    "    phrase_list = []\n",
    "    for sentence in text:\n",
    "        # replace stopwords with | in order to break sentences up\n",
    "        tmp = re.sub(stopword_regex, '|', sentence.strip())\n",
    "        phrases = tmp.split(\"|\")\n",
    "        for phrase in phrases:\n",
    "            phrase = phrase.strip().lower()\n",
    "            phrase = ' '.join(phrase.split())\n",
    "            if phrase != \"\":\n",
    "                phrase_list.append(phrase)\n",
    "    phrase_list = [phrase for phrase in phrase_list if re.search(r'\\w+', phrase)]\n",
    "    \n",
    "    return phrase_list\n",
    "\n",
    "def remove_starting_symbol(phrase_list):\n",
    "    \"\"\"\n",
    "    :remove starting symbols or numbers from phrases e.g '“whilst rewearing' or '-based website'\n",
    "    \"\"\"\n",
    "    phrase_list_cleaned = []\n",
    "    \n",
    "    for phrase in phrase_list:\n",
    "        try:\n",
    "            while not phrase[0].isalpha():\n",
    "                phrase = phrase[1:]\n",
    "        except IndexError:\n",
    "            pass\n",
    "        phrase_list_cleaned.append(phrase)\n",
    "            \n",
    "    return phrase_list_cleaned\n",
    "\n",
    "def remove_single_character_phrase(phrase_list):\n",
    "    \n",
    "    phrase_list_cleaned = [phrase for phrase in phrase_list if len(phrase) > 1]\n",
    "            \n",
    "    return phrase_list_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "35872ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopword_regex = build_stop_word_regex()\n",
    "test = generate_phrases(test, stopword_regex)\n",
    "#test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf89d7a6",
   "metadata": {},
   "source": [
    "### Combined Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f75fc43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocessing(df):\n",
    "    df_new = df.copy()\n",
    "    df_new['content_processed'] = ''\n",
    "    \n",
    "    stopword_regex = build_stop_word_regex()\n",
    "    \n",
    "    for idx, content in enumerate(df_new['content']):\n",
    "        #print(idx, 'content: \\n',content, '\\n')\n",
    "        text = remove_emails_tags(content)\n",
    "        #print('emails: \\n',text, '\\n')\n",
    "        text = remove_numbers(text)\n",
    "        #print('numbers: \\n', text, '\\n')\n",
    "        text = remove_contraction_possesive_apostrophes(text)\n",
    "        text = split_sentences(text)\n",
    "        #print('split sentences: \\n', text, '\\n')\n",
    "        text = generate_phrases(text, stopword_regex)\n",
    "        text = remove_starting_symbol(text)\n",
    "        #print('PHRASES: \\n', text, '\\n')\n",
    "        text = remove_single_character_phrase(text)\n",
    "        df_new.at[idx, 'content_processed'] = text\n",
    "        if idx % 25000 == 0:\n",
    "            print(f'{idx} records processed')\n",
    "    \n",
    "    return df_new\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253df704",
   "metadata": {},
   "source": [
    "# Complete Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bfdf8fd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 records processed\n",
      "25000 records processed\n",
      "50000 records processed\n",
      "75000 records processed\n",
      "100000 records processed\n",
      "125000 records processed\n",
      "150000 records processed\n",
      "175000 records processed\n",
      "200000 records processed\n",
      "225000 records processed\n",
      "250000 records processed\n",
      "275000 records processed\n",
      "300000 records processed\n",
      "325000 records processed\n",
      "350000 records processed\n"
     ]
    }
   ],
   "source": [
    "# ~ 1 hour to run\n",
    "df_processed = data_preprocessing(df)\n",
    "df_processed.to_pickle('./Data/df_processed.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6b3b43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfabc675",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d608b1f2",
   "metadata": {},
   "source": [
    "# TO DO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac2a5c8",
   "metadata": {},
   "source": [
    "### Strip company names out of text\n",
    "Just an idea to come back to because otherwise they may form significance for topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "7b82beb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With the end of the year just around the corner, it’s past time to think about positioning for2020. When it comes to earnings power in 2020, the Industrial sector is going to be the market leader and that is where I like my money to be. To be clear, when I say Industrial Sector I mean the S&P 500 Industrial Sector as represented by the ETF (XLI). Yes, the Energy Sector is expected to post EPS growth double that of the Industrials but investors should take that news with a grain of salt. The Energy Sector’s (XLE) consensus EPS growth estimate for 2020 is 21% but only after falling -28% this year. The Industrial Sector is expected to grow by 15% next year (2nd fastest pace for the S&P 500) after contracting only -3% this year. That means the Energy Sector’s earnings will still be down on a two-year basis while the Industrial’s will rise. Energy may yet turn out to be a good investment for 2020 but, on an earnings basis, the Industrials are a much better choice. Don’t Bet On Boeing Boeing (BA) is by far the largest holding within the Industrial Sector SPDR but not an investment I recommend at this time. At just over 8% it outweighs the #2 holding, Honeywell (HON), by nearly 200 basis points and that is why the XLI is not the best choice for investors today. With the 737-Max scandal still raging it is unlikely Boeing will back in 2020. The most recent news on that front is the ousting of CEO Dennis Muilenberg. Muilenberg has been in charge of Boeing since 2015 and key to the 737-Max crisis, the board decided it was in the company’s best interest to find someone else. document.write('<a style=\"text-decoration:none;font-weight:normal;color:#696969;\" target=\"_blank\" rel=\"nofollow\" href=\"https://www.ame' + 'ricanconsumernews.net/scripts/click.aspx?NativeDisplayAdID=584&ImpressionID=0&UserID=0&Placement=PlaceOnArticlePage\">');Buffett is notoriously “anti technology.” Which is why this Wall Street Legend's recent discover is so shocking:\n",
      "21 of Buffett’s 25 current favorite companies are going “all in” one hot new technology… To the tune of $1.7 billion! ...After decades of being anti-tech...what is making Buffett going all in now? And what is this new technology that America's biggest companies are in a race to implement? There are several stocks within the XLI portfolio on the move and looking bullish. The three I want to highlight today are uniquely set up for 2020 and we can give thanks to the trade war for that. Caterpillar (CAT), Deere & Company (DE), and Cummins Inc (CMI) have all seen their business deteriorate due to the trade war issuing downgrades and missing estimates. Now, with the Phase One Deal in sight, that is all about to change. Once the deal is signed and the details are well known we can expect to see a flurry of analysts upgrades for these stocks and this sector. Cummins Inc, On The Move Cummins Inc is a maker of engines and components for heavy industrial trucks. The company has been suffering due to softening demands for those trucks but you wouldn’t think so looking at the share price. The price of Cummins has risen nearly 30% since hitting a bottom last August and looks ready to continue rising in 2020. The outlook for growth, and the impact of the Phase One Deal on that outlook, are only part of the reason Cummins is on the move. Cummins is also a solid dividend payer and a prolific buyer of its own stock so a great way to capitalize on this industry. At today’s prices, the stock yields close to 3% and has a 14-year  history of distribution increases. The XLI only pays aobut 1.9%. As for buybacks, the board just announced another $2 billion in buybacks slated for 2020. Deere & Company, China Is The Key To Growth Deere & Company, that iconic maker of tractors, recently downgraded its outlook for 2020 due to the trade war. The company says lingering trade tensions played a big roll in the decision which makes the Phase One Deal of particular importance. The idea is that, once the Phase One Deal is signed, trade with China will reinvigorate growth globally, not just in the China segment of the business. Looking at the earnings picture, Deere & Company will be one of 2020’s best EPS growers despite the recent downgrade to guidance. The consensus estimate for EPS is $11.02, a 27% increase from 2019. Like Cummins, Deere & Company is a dividend payer and an attractive one at that. The yield is a little low, only 1.75% at today’s prices, but it is a safe 1.75%. The payout ratio is only 27% of next year’s earnings which also leaves plenty of room for an increase. Caterpillar, A Dividend Aristocrat For Capital Gains In 2020 Shares of Caterpillar have been on the move in the second half of 2019 too. The stock is up more than 31% in the last four months and may easily match that gain in 2020. While the business has been struggling this year, the impact of tariffs has not been as great as feared. In addition, Caterpillar’s CEO says many of its businesses have “significant potential upside.” On a technical basis, the stock is forming a Bullish Flag Pattern with a $36 flag-pole. If, when, the pattern confirms traders can expect the stock to rise as much as or more than $36. Such a move would put the stock at a new all-time high. Regarding the dividend, Caterpillar is a Dividend Aristocrat with 26 years of distribution increases under its belt. The yield at today's prices is about 2.8% with a low 38% payout ratio. 6 Stocks That Will Benefit From a Dovish Federal Reserve The quaint correction that was labeled the “tech wreck” of 2018 seems like a distant memory to investors. What also seems like a distant memory is any thought of the Federal Reserve raising interest rates.\n",
      "\n",
      "At the end of 2018, the Federal Reserve had raised its benchmark federal funds rate. With the trade dispute with China dragging on, there was increasing pressure on the Fed to lower interest rates. When interest rates are lower, stocks will generally rise as investors have no other option for growth.\n",
      "\n",
      "In July 2019, the doves got their wish. But in a move that now seems to be a “what did they know move”, the Fed dropped rates again in October. The market soared to record highs in January and early February. Since mid-February however, the market has fallen dramatically, and the Fed juiced the market one more time by cutting rates down to levels not seen since the financial crisis.\n",
      "\n",
      "None of us know for sure when the U.S. economy will be opened up. And while stocks are still a good investment, not every stock is a smart investment at this time. But some stocks perform well when interest rates are falling and that’s why we’ve prepared this presentation.\n",
      "\n",
      "These six stocks stand to benefit from both low-interest rates and the unique economic conditions being brought on by the Covid-19 pandemic. View the \"6 Stocks That Will Benefit From a Dovish Federal Reserve\". Complete the form below to receive the latest headlines and analysts' recommendations for your stocks with our free daily email newsletter:\n"
     ]
    }
   ],
   "source": [
    "print(df['content'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af18943",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
