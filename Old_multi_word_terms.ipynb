{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34032a0a-f830-4333-8e51-7d1e6d9f33a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sentences(text):\n",
    "    \"\"\"\n",
    "    return a list of sentences from text based on common separators\n",
    "    \"\"\"\n",
    "    sentence_delimiters = re.compile(u'[.!?,;:\\t\\\\\\\\\"\\\\(\\\\)\\\\\\'\\u2019\\u2013]|\\\\s\\\\-\\\\s')\n",
    "    sentences = sentence_delimiters.split(text)\n",
    "    \n",
    "    return sentences\n",
    "\n",
    "test = split_sentences(test)\n",
    "#test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea933c7f-c486-415e-9359-dc78358532f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_stop_word_regex():\n",
    "    \"\"\"\n",
    "    :used in function generate_phrases to remove stopwords before\n",
    "    compiling multi word phrases\n",
    "    \"\"\"\n",
    "    stop_word_list = spacy.lang.en.stop_words.STOP_WORDS\n",
    "    stop_word_regex_list = []\n",
    "    for word in stop_word_list:\n",
    "        word_regex = r'\\b' + word + r'(?![\\w-])'\n",
    "        stop_word_regex_list.append(word_regex)\n",
    "    stop_word_pattern = re.compile('|'.join(stop_word_regex_list), re.IGNORECASE)\n",
    "    return stop_word_pattern\n",
    "\n",
    "def generate_phrases(text, stopword_regex):\n",
    "    \"\"\"\n",
    "    :compile list of multi word phrases by splitting sentences on stopwords\n",
    "    \"\"\"\n",
    "    \n",
    "    phrase_list = []\n",
    "    for sentence in text:\n",
    "        # replace stopwords with | in order to break sentences up\n",
    "        tmp = re.sub(stopword_regex, '|', sentence.strip())\n",
    "        phrases = tmp.split(\"|\")\n",
    "        for phrase in phrases:\n",
    "            phrase = phrase.strip().lower()\n",
    "            phrase = ' '.join(phrase.split())\n",
    "            if phrase != \"\":\n",
    "                phrase_list.append(phrase)\n",
    "    phrase_list = [phrase for phrase in phrase_list if re.search(r'\\w+', phrase)]\n",
    "    \n",
    "    return phrase_list\n",
    "\n",
    "def remove_starting_symbol(phrase_list):\n",
    "    \"\"\"\n",
    "    :remove starting symbols or numbers from phrases e.g 'â€œwhilst rewearing' or '-based website'\n",
    "    \"\"\"\n",
    "    phrase_list_cleaned = []\n",
    "    \n",
    "    for phrase in phrase_list:\n",
    "        try:\n",
    "            while not phrase[0].isalpha():\n",
    "                phrase = phrase[1:]\n",
    "        except IndexError:\n",
    "            pass\n",
    "        phrase_list_cleaned.append(phrase)\n",
    "            \n",
    "    return phrase_list_cleaned\n",
    "\n",
    "def remove_single_character_phrase(phrase_list):\n",
    "    \n",
    "    phrase_list_cleaned = [phrase for phrase in phrase_list if len(phrase) > 1]\n",
    "            \n",
    "    return phrase_list_cleaned\n",
    "\n",
    "\n",
    "# Combined function of above\n",
    "def find_multi_word_terms(df):\n",
    "    df = df.copy()\n",
    "    df['mwt'] = ''\n",
    "    \n",
    "    stopword_regex = build_stop_word_regex()\n",
    "    \n",
    "    for idx, content in enumerate(df['content_processed']):\n",
    "        text = generate_phrases(text, stopword_regex)\n",
    "        text = remove_starting_symbol(text)\n",
    "        #print('PHRASES: \\n', text, '\\n')\n",
    "        text = remove_single_character_phrase(text)\n",
    "        df_new.at[idx, 'content_processed'] = text\n",
    "        if idx % 25000 == 0:\n",
    "            print(f'{idx} records processed')\n",
    "    \n",
    "    return df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba98b1a-1f3f-4df2-b0ec-425d2268d873",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopword_regex = build_stop_word_regex()\n",
    "test = generate_phrases(test, stopword_regex)\n",
    "#test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
